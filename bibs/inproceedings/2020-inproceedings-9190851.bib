@inproceedings{9190851,
 abbr = {IEEE Conference},
 abstract = {In the blooming era of smart edge devices, surveillance cameras have been deployed in many locations. Surveillance cameras are most useful when they are spaced out to maximize coverage of an area. However, deciding where to place cameras is an NP-hard problem and researchers have proposed heuristic solutions. Existing work does not consider a significant restriction of computer vision: in order to track a moving object, the object must occupy enough pixels. The number of pixels depends on many factors (How far away is the object? What is the camera resolution? What is the focal length?). In this study, we propose a camera placement method that identifies effective camera placement in arbitrary spaces and can account for different camera types as well. Our strategy represents spaces as polygons, then uses a greedy algorithm to partition the polygons and determine the camerasâ€™ locations to provide the desired coverage. Our solution also makes it possible to perform object tracking via overlapping camera placement. Our method is evaluated against complex shapes and real-world museum floor plans, achieving up to 85\% coverage and 25\% overlap.},
 author = {Aghajanzadeh, Sara and Naidu, Roopasree and Chen, Shuo-Han and Tung, Caleb and Goel, Abhinav and Lu, Yung-Hsiang and Thiruvathukal, George K.},
 booktitle = {2020 IEEE International Conference on Image Processing (ICIP)},
 doi = {10.1109/ICIP40778.2020.9190851},
 url = {http://ecommons.luc.edu/cs_facpubs/250},
 pdf = {http://ecommons.luc.edu/cs_facpubs/250},
 html = {http://ecommons.luc.edu/cs_facpubs/250},
 issn = {2381-8549},
 month = {10},
 pages = {3254-3258},
 title = {Camera Placement Meeting Restrictions of Computer Vision},
 year = {2020}
}

